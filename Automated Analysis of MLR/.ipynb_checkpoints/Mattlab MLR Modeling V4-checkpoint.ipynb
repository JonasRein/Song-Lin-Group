{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to use this script:\n",
    "\n",
    "Run every cell moving down the notebook until section 4.2 to generate a list of MLR models for a property of interest. The user has several opportunities to modify variable values in Sections 2.1, 3.1, and 4.1.1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T03:53:31.940766Z",
     "start_time": "2019-07-07T03:53:31.935868Z"
    }
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-15T22:34:18.768587Z",
     "start_time": "2019-07-15T22:34:18.725225Z"
    }
   },
   "outputs": [],
   "source": [
    "import os, re, sys, pickle, datetime\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA,NMF\n",
    "from sklearn.ensemble import RandomForestClassifier,RandomForestRegressor,GradientBoostingRegressor\n",
    "from sklearn.feature_selection import SelectKBest,f_regression,mutual_info_regression\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.linear_model import LogisticRegression,Lasso,LinearRegression,Ridge,ElasticNetCV,ElasticNet,Lars,LassoCV,RidgeCV,LarsCV,LassoLarsCV,LassoLarsIC,OrthogonalMatchingPursuitCV,OrthogonalMatchingPursuit\n",
    "from sklearn.manifold import TSNE,MDS\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix,f1_score\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV,RepeatedKFold,LeaveOneOut,cross_val_score,cross_validate\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier,MLPRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler,PolynomialFeatures\n",
    "from sklearn.svm import LinearSVC,SVR\n",
    "from sklearn.tree import DecisionTreeClassifier,DecisionTreeRegressor\n",
    "#from sklearn import tree\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import multiprocessing\n",
    "nproc = max([1,multiprocessing.cpu_count()-2])\n",
    "from joblib import Parallel,delayed\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# import loo_q2 Python file.\n",
    "import loo_q2 as loo\n",
    "\n",
    "randomstate = 42\n",
    "\n",
    "def plot_fit(y_train,y_pred_train,y_test,y_pred_test,leg=True,sav=False,label=\"y\",loo_pred=[]):\n",
    "    y_orig_min = np.min(np.hstack((y_train,y_test)))\n",
    "    y_pred_min = np.min(np.hstack((y_pred_train,y_pred_test)))\n",
    "    y_orig_max = np.max(np.hstack((y_train,y_test)))\n",
    "    y_pred_max = np.max(np.hstack((y_pred_train,y_pred_test)))\n",
    "    delta_x = 0.04 * (y_orig_max-y_orig_min)\n",
    "    delta_y = 0.04 * (y_pred_max-y_pred_min)\n",
    "           \n",
    "    yy_fit = np.polyfit(y_train,y_pred_train,deg=1)\n",
    "    yy_fit_line = yy_fit[1]+yy_fit[0]*y_train\n",
    "    \n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.plot(np.linspace(y_orig_min-delta_x,y_orig_max+delta_x), np.linspace(y_orig_min-delta_x,y_orig_max+delta_x),color=\"grey\")\n",
    "    plt.xlim([y_orig_min-delta_x,y_orig_max+delta_x])\n",
    "    plt.ylim([y_pred_min-delta_y,y_pred_max+delta_y])\n",
    "    if len(loo_pred) != 0:\n",
    "        plt.scatter(y_train,loo_train,label=\"LOO\",color=\"black\",marker=\"s\",facecolor='none')\n",
    "    plt.scatter(y_train,y_pred_train,label=\"training\",color=\"black\",marker=\"s\") # ,alpha=0.6\n",
    "    plt.scatter(y_test,y_pred_test,label=\"test\",color=\"red\",marker=\"s\")     #,alpha=0.25\n",
    "    plt.plot(y_train,yy_fit_line,color=\"black\") #,alpha=0.2\n",
    "    if leg:\n",
    "        plt.legend(loc='lower right')\n",
    "    plt.xlabel(label+\" measured\",fontsize=20)\n",
    "    plt.ylabel(label+\" predicted\",fontsize=20)\n",
    "    \n",
    "#     plt.xticks([])\n",
    "#     plt.yticks([])\n",
    "    \n",
    "    if not sav:\n",
    "        plt.show()  \n",
    "    else:\n",
    "        plt.savefig(sav)\n",
    "        \n",
    "def r2_val(y_test,y_pred_test,y_train):\n",
    "    \"\"\"Calculates the external R2 pred as described:\n",
    "    https://pdfs.semanticscholar.org/4eb2/5ff5a87f2fd6789c5b9954eddddfd1c59dab.pdf\"\"\"\n",
    "    y_resid = y_pred_test - y_test\n",
    "    SS_resid = np.sum(y_resid**2)\n",
    "    y_var = y_test - np.mean(y_train)\n",
    "    SS_total = np.sum(y_var**2)\n",
    "    r2_validation = 1-SS_resid/SS_total\n",
    "    return(r2_validation)\n",
    "\n",
    "def repeated_k_fold(X_train,y_train,reg = LinearRegression(), k=3, n=100):\n",
    "    \"\"\"Reapeated k-fold cross-validation. \n",
    "    For each of n repeats, the (training)data is split into k folds. \n",
    "    For each fold, this part of the data is predicted using the rest. \n",
    "    Once this is done for all k folds, the coefficient of determination (R^2) of the predictions of all folds combined (= the complete data set) is evaluated\n",
    "    This is repeated n times and all n R^2 are returned for averaging/further analysis\n",
    "    \"\"\"\n",
    "    \n",
    "    rkf = RepeatedKFold(n_splits=k, n_repeats=n)\n",
    "    r2_scores = []\n",
    "    y_validations,y_predictions = np.zeros((np.shape(X_train)[0],n)),np.zeros((np.shape(X_train)[0],n))\n",
    "    foldcount = 0\n",
    "    for i,foldsplit in enumerate(rkf.split(X_train)):\n",
    "        fold, rep = i%k, int(i/k) # Which of k folds. Which of n repeats\n",
    "        model = reg.fit(X_train[foldsplit[0]],y_train[foldsplit[0]]) # foldsplit[0]: k-1 training folds\n",
    "        y_validations[foldcount:foldcount+len(foldsplit[1]),rep] = y_train[foldsplit[1]] # foldsplit[1]: validation fold\n",
    "        y_predictions[foldcount:foldcount+len(foldsplit[1]),rep]  = model.predict(X_train[foldsplit[1]])\n",
    "        foldcount += len(foldsplit[1])\n",
    "        if fold+1==k:\n",
    "            foldcount = 0\n",
    "    r2_scores = np.asarray([metrics.r2_score(y_validations[:,rep],y_predictions[:,rep]) for rep in range(n)])\n",
    "    return(r2_scores)\n",
    "\n",
    "# keepmodels = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-15T19:44:31.116959Z",
     "start_time": "2019-07-15T19:44:31.011638Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_samples before removing empty cells: 26\n",
      "Removing 1 samples.\n",
      "Shape X: (25, 374)\n",
      "Shape y: (25,)\n",
      "Shape labels: (25,)\n",
      "First X cell: 12.2939\n",
      "Last X cell:  0.6876583333333333\n",
      "First y: 150.0\n",
      "Last y:  252.0\n",
      "Last label: 618_SEVTOEÂ .txt\n"
     ]
    }
   ],
   "source": [
    "# all data in a single file\n",
    "excel_file = \"Nitramines (26) All Data Td (with full NBO)\"\n",
    "excel_sheet = \"Tabelle1\"\n",
    "num_par = 374 # number of descriptors\n",
    "par_start_col = 2 # 0-indexed\n",
    "num_samples = 26 # number of compounds\n",
    "response_col = 1 # 0-indexed\n",
    "y_label_col = 0 # 0-indexed\n",
    "\n",
    "apply_mask = True # remove samples with empty response\n",
    "verbose = True\n",
    "xlabelrow = True\n",
    "\n",
    "inp = pd.read_excel(excel_file+\".xlsx\",excel_sheet,header=0,index_col=y_label_col,nrows=num_samples+int(xlabelrow),\n",
    "                    usecols=list(range(0,(num_par+par_start_col))))\n",
    "# remove columns from dataframe that contain only zeros. these features will not contribute to the MLR model.\n",
    "inp = inp.loc[:, (inp != 0).any(axis = 0)]\n",
    "\n",
    "if xlabelrow:\n",
    "    X_names = list(inp.iloc[0,par_start_col-1:num_par+par_start_col-1])\n",
    "    X_labels = list(inp.columns)[par_start_col-1:num_par+par_start_col-1]\n",
    "    resp_label = list(inp.columns)[response_col-1]\n",
    "    inp.drop(index=inp.index[0],inplace=True)\n",
    "else:\n",
    "    X_labels = list(inp.columns)[par_start_col-1:num_par+par_start_col-1]\n",
    "    X_names = X_labels\n",
    "    resp_label = list(inp.columns)[response_col-1]\n",
    "\n",
    "X_labelname = [\" \".join(i) for i in zip(X_labels,X_names)] \n",
    "X_labelname_dict = dict(zip(X_labels,X_names))\n",
    "y = np.asarray(inp[resp_label],dtype=np.float)\n",
    "X = np.asarray(inp[X_labels],dtype=np.float)\n",
    "y_labels = np.asarray(list(inp.index),dtype=str)\n",
    "y_labels_comp= y_labels\n",
    "\n",
    "if apply_mask:\n",
    "    mask = y.nonzero()[0]\n",
    "    mask = ~np.isnan(y)\n",
    "    print(\"n_samples before removing empty cells: {}\".format(len(y)))\n",
    "    print(\"Removing {} samples.\".format(len(y)-sum(mask)))\n",
    "    X = X[np.array(mask)]\n",
    "    y = y[np.array(mask)]\n",
    "    y_labels = y_labels[np.array(mask)]\n",
    "X_all = X\n",
    "if verbose:\n",
    "    print(\"Shape X: {}\".format(X.shape))\n",
    "    print(\"Shape y: {}\".format(y.shape)) \n",
    "    print(\"Shape labels: {}\".format(y_labels.shape)) \n",
    "    print(\"First X cell: {}\".format(X[0,0]))\n",
    "    print(\"Last X cell:  {}\".format(X[-1,-1]))\n",
    "    print(\"First y: {}\".format(y[0]))\n",
    "    print(\"Last y:  {}\".format(y[-1]))\n",
    "    print(\"Last label: {}\".format(y_labels[-1]))\n",
    "    #print(inp.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation: Training/Test set split, Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training/Test set split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-15T20:02:08.375756Z",
     "start_time": "2019-07-15T20:02:08.269464Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TS: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]\n",
      "VS: []\n",
      "y_mean TS: 191.920\n",
      "y_mean VS: nan\n",
      "Shape X_train: (25, 374)\n",
      "Shape X_test:  (0, 374)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# comment this line out if preselection was performed\n",
    "X_sel,y_sel,labels_sel,exclude = X,y,y_labels,[]\n",
    "\n",
    "# select method of split:\n",
    "# random\n",
    "# y_equidist - picks points that evenly span the output variable y. \n",
    "#              Normally doesn't pick highest/lowest values but this can be activated by changing the variable no_extrapolation in the respective section\n",
    "# ks - Kennard Stone algorithm picks points based on an even distriution in feature space\n",
    "# define - give a list of sample indices for either VS or TS in the corresponding code section \n",
    "# none - all samples in TS\n",
    "\n",
    "# the numbers in the variables VS and TS refer to the original 0-indexed sample numbers \n",
    "\n",
    "split = \"none\" # select desired test/training split algorithm. Kennard-Stone works well.\n",
    "test_ratio = 0.25\n",
    "\n",
    "if split == \"random\":\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_sel, y_sel, random_state=randomstate+3, test_size=test_ratio)    \n",
    "    TS = [np.argwhere(np.all(X==i,axis=1))[0,0] for i in X_train]\n",
    "    VS = [np.argwhere(np.all(X==i,axis=1))[0,0] for i in X_test]\n",
    "    \n",
    "elif split == \"define\":\n",
    "    # numbers according to sample lines in the excel sheet (that is, including indexes of 'excluded' samples)\n",
    "    # for defining the TS, change the names of TS and VS in the next three lines\n",
    "    TS = [1,2,3]\n",
    "    \n",
    "    TS = [i-1 for i in VS] # this can be commented out if 0-indexed numbers were defined above\n",
    "    VS = [i for i in range(X.shape[0]) if i not in VS and i not in exclude]\n",
    "    X_train, y_train,X_test, y_test = X[TS],y[TS],X[VS],y[VS]\n",
    "    \n",
    "elif split == \"ks\":\n",
    "    # import Kennard-Stone Python file.\n",
    "    import kennardstonealgorithm as ks\n",
    "    TS,VS = ks.kennardstonealgorithm(X_sel,int((1-test_ratio)*np.shape(X_sel)[0]))\n",
    "    X_train, y_train,X_test, y_test = X_sel[TS], y_sel[TS],X_sel[VS], y_sel[VS]\n",
    "  \n",
    "    TS = [np.argwhere(np.all(X==i,axis=1))[0,0] for i in X_train]\n",
    "    VS = [np.argwhere(np.all(X==i,axis=1))[0,0] for i in X_test]   \n",
    "\n",
    "elif split == \"y_equidist\":\n",
    "    no_extrapolation = True\n",
    "    \n",
    "    import kennardstonealgorithm as ks\n",
    "    if no_extrapolation:\n",
    "        minmax = [np.argmin(y_sel),np.argmax(y_sel)]\n",
    "        y_ks = np.array(([i for i in y_sel if i not in [np.min(y_sel),np.max(y_sel)]]))\n",
    "        y_ks_indices = [i for i in range(len(y_sel)) if i not in minmax]\n",
    "        \n",
    "        # indices relative to y_ks:\n",
    "        VS_ks,TS_ks = ks.kennardstonealgorithm(y_ks.reshape(np.shape(y_ks)[0],1),int((test_ratio)*(2+np.shape(y_ks)[0])))\n",
    "        # indices relative to y_sel:\n",
    "        TS_ = sorted([y_ks_indices[i] for i in list(TS_ks)]+minmax)\n",
    "        VS_ = sorted([y_ks_indices[i] for i in VS_ks])\n",
    "\n",
    "    else:\n",
    "        VS_,TS_ = ks.kennardstonealgorithm(y_sel.reshape(np.shape(y_sel)[0],1),int((test_ratio)*np.shape(y_sel)[0]))\n",
    "    \n",
    "    X_train, y_train,X_test, y_test = X_sel[TS_], y_sel[TS_],X_sel[VS_], y_sel[VS_]\n",
    "    \n",
    "    # indices relative to y\n",
    "    TS = [np.argwhere(np.all(X==i,axis=1))[0,0] for i in X_train]\n",
    "    VS = [np.argwhere(np.all(X==i,axis=1))[0,0] for i in X_test]\n",
    "\n",
    "elif split == \"none\":\n",
    "    TS, VS = [i for i in range(X.shape[0]) if i not in exclude],[]\n",
    "    X_train, y_train, X_test, y_test = X[TS],y[TS],X[VS],y[VS]\n",
    "    \n",
    "else: \n",
    "    raise ValueError(\"split option not recognized\")\n",
    "     \n",
    "\n",
    "print(\"TS: {}\".format(TS))\n",
    "print(\"VS: {}\".format(VS))\n",
    "print(\"y_mean TS: {:.3f}\".format(np.mean(y_train)))\n",
    "print(\"y_mean VS: {:.3f}\".format(np.mean(y_test)))\n",
    "print(\"Shape X_train: {}\".format(X_train.shape))\n",
    "print(\"Shape X_test:  {}\".format(X_test.shape))   \n",
    "plt.figure(figsize=(5, 5))\n",
    "hist,bins = np.histogram(y_sel,bins=\"auto\")#\"auto\"\n",
    "plt.hist(y_train, bins, alpha=0.5, label='y_train',color=\"black\")\n",
    "plt.hist(y_test, bins, alpha=0.5, label='y_test')\n",
    "# plt.legend(loc='best')\n",
    "plt.xlabel(\"y\",fontsize=20)\n",
    "plt.ylabel(\"N samples\",fontsize=20)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.show()\n",
    "\n",
    "print(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-15T20:03:07.252006Z",
     "start_time": "2019-07-15T20:03:07.246283Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 374)) while a minimum of 1 is required by StandardScaler.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-070b1ad5e6d0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# scaler = MinMaxScaler()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mX_train_sc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mX_test_sc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mX_all_sc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_all\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, X, copy)\u001b[0m\n\u001b[0;32m    793\u001b[0m         X = check_array(X, accept_sparse='csr', copy=copy,\n\u001b[0;32m    794\u001b[0m                         \u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 795\u001b[1;33m                         force_all_finite='allow-nan')\n\u001b[0m\u001b[0;32m    796\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    797\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    584\u001b[0m                              \u001b[1;34m\" minimum of %d is required%s.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m                              % (n_samples, array.shape, ensure_min_samples,\n\u001b[1;32m--> 586\u001b[1;33m                                 context))\n\u001b[0m\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mensure_min_features\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 374)) while a minimum of 1 is required by StandardScaler."
     ]
    }
   ],
   "source": [
    "# scale features by mean/variance, pick the relevant option (normally: StandardScaler)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "# scaler = MinMaxScaler()\n",
    "X_train_sc = scaler.fit_transform(X_train)\n",
    "X_test_sc = scaler.transform(X_test)\n",
    "X_all_sc = scaler.transform(X_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-terms/Interaction terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add polynomial features/interaction terms\n",
    "# this is not yet implemented properly in some sections. \n",
    "# for 5.1-manual selection: specify cross-term with space between the components: x1 x40 + x6\n",
    "# Essentially only section 5.2 can use cross-terms so far\n",
    "# don't run this twice\n",
    "\n",
    "polyfeats = PolynomialFeatures(degree=2,interaction_only=False,include_bias=False)\n",
    "X_train_p = polyfeats.fit_transform(X_train_sc)\n",
    "X_test_p = polyfeats.transform(X_test_sc)\n",
    "X_all_p = polyfeats.transform(X_all_sc)\n",
    "\n",
    "def add_to_x(matchobj):\n",
    "    if \"^\" in matchobj.group(0):\n",
    "        n = int(matchobj.group(0).split(\"^\")[0])+1\n",
    "        return(\"{} x{}\".format(n,n))\n",
    "    else:\n",
    "        return(str(int(matchobj.group(0))+1))\n",
    "    \n",
    "pfnames = np.asarray([re.sub(\"[0-9]+(\\^[0-9])*\",add_to_x,st) for st in polyfeats.get_feature_names()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out non-significant crossterms based on p-value with target variable\n",
    "p_val_cutoff = 0.05\n",
    "\n",
    "r2s = []\n",
    "pvals = []\n",
    "for f_ind,feature in enumerate(X_train_p.T):\n",
    "    slope, intercept, r_value, p_value, std_err = stats.linregress(feature, y_train)    \n",
    "    r2s.append(r_value**2)\n",
    "    pvals.append(p_value)\n",
    "    \n",
    "r2s_ = np.asarray(r2s)\n",
    "pvals_ = np.asarray(pvals)\n",
    "\n",
    "keep_p_ = [i[0] for i in np.argwhere(pvals_<p_val_cutoff) if i not in range(np.shape(X_all)[1])]\n",
    "keep_p = [i for i in range(np.shape(X_all)[1])] + keep_p_\n",
    "\n",
    "def sub_label_to_name(matchobj):\n",
    "    return(X_labelname_dict[matchobj.group(0)])\n",
    "def sub_labelname(matchobj):\n",
    "    return(matchobj.group(0)+\" \"+X_labelname_dict[matchobj.group(0)])\n",
    "    \n",
    "pfnames = np.asarray([re.sub(\"[0-9]+(\\^[0-9])*\",add_to_x,st) for st in polyfeats.get_feature_names()])\n",
    "X_p_labels = list(np.reshape(pfnames[keep_p],len(keep_p)))\n",
    "X_p_names = [re.sub(\"x[0-9]+\",sub_label_to_name,st) for st in X_p_labels]\n",
    "X_p_labelname = [re.sub(\"x[0-9]+\",sub_labelname,st) for st in X_p_labels]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "# scaler = MinMaxScaler()\n",
    "X_train_sc = scaler.fit_transform(X_train_p[:,keep_p])\n",
    "X_test_sc = scaler.transform(X_test_p[:,keep_p])\n",
    "X_all_sc = scaler.transform(X_all_p[:,keep_p])\n",
    "\n",
    "X_labels = X_p_labels\n",
    "X_names = X_p_names\n",
    "X_labelname = X_p_labelname\n",
    "\n",
    "print(\"{} cross-terms with p-value < {}\".format(len(keep_p_),p_val_cutoff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write dataframe to obtain meanings of cross-terms.\n",
    "x_labels_df = pd.DataFrame(X_labels)\n",
    "x_names_df = pd.DataFrame(X_names)\n",
    "x_labelname_df = pd.DataFrame(X_labelname)\n",
    "cross_terms_df = pd.concat([x_labels_df, x_names_df, x_labelname_df], axis = 1)\n",
    "cross_terms_df.to_excel('Cross terms.xlsx')\n",
    "\n",
    "# reorganize all descriptors (single, cross-terms) into dataframe.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear modeling, feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward stepwise selection keeping a set of candidates at each step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T03:29:59.485960Z",
     "start_time": "2019-11-26T03:29:59.449406Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1\n",
      "Step 2\n",
      "Finished 1 and 2 parameter models. Time taken (sec): 47.5807\n",
      "Step 3\n",
      "cutpar:  1\n",
      "cutpar:  1\n",
      "cutpar:  1\n",
      "Step 4\n",
      "cutpar:  1\n",
      "cutpar:  1\n",
      "cutpar:  1\n",
      "Done. Time taken (minutes): 2.52\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_test_sc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-0e3dcd446f39>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[0mselected_feats\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mX_labels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodel_sel\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mterms\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[0mX_train_sel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train_sc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mselected_feats\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[0mX_test_sel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_test_sc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mselected_feats\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\n\\nBest model:\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodel_sel\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformula\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_test_sc' is not defined"
     ]
    }
   ],
   "source": [
    "# Forward stepwise selection keeping a set of candidates at each step\n",
    "n_steps = 4 # number of terms in model.\n",
    "n_candidates = 20 # number of candidates for each model of n terms.\n",
    "collin_criteria = 0.3 # can be modified. this is R2\n",
    "skipfeatures = [] #[\"x4\",\"x3\"]\n",
    "\n",
    "# import ForwardStepCandidates Python file.\n",
    "import ForwardStepCandidates_2 as fsc\n",
    "df = pd.DataFrame(np.hstack((X_train_sc,y_train[:,None])))\n",
    "newcols = [\"x\"+str(i+1) for i in df.columns.values]\n",
    "df.columns = newcols\n",
    "response = newcols[-1]\n",
    "df.rename(columns={response:\"y\"},inplace=True)\n",
    "df.drop(skipfeatures,axis=1,inplace=True)\n",
    "\n",
    "# add coefficients output for interpretability.\n",
    "\n",
    "results,models,scores,sortedmodels,candidates = fsc.ForwardStep_py(df,'y',\n",
    "                    n_steps=n_steps,n_candidates=n_candidates,collin_criteria=collin_criteria)\n",
    "model_sel = results.loc[0,\"Model\"]\n",
    "selected_feats = [X_labels.index(i) for i in models[model_sel].terms]\n",
    "X_train_sel = X_train_sc[:,selected_feats]\n",
    "X_test_sel = X_test_sc[:,selected_feats]\n",
    "print(\"\\n\\nBest model:\")\n",
    "print(models[model_sel].formula)\n",
    "print(\"1 + \"+\" + \".join([X_names[X_labels.index(i)] for i in models[candidates[0]].terms])+\"\\n\")\n",
    "lr = LinearRegression().fit(X_train_sel,y_train)\n",
    "y_pred_train = lr.predict(X_train_sel)\n",
    "y_pred_test =  lr.predict(X_test_sel)\n",
    "\n",
    "q2,loo_train = loo.q2(X_train_sel,y_train)\n",
    "kfoldscores_self = repeated_k_fold(X_train_sel,y_train,k=5,n=100)\n",
    "\n",
    "print(\"Features: \" + \" + \".join([\"x\"+str(i+1) for i in sorted(selected_feats)]))\n",
    "print(\"\\nParameters:\\n{:10.4f} + \\n\".format(lr.intercept_) + \"\\n\".join([\"{:10.4f} * {}\".format(lr.coef_[i],X_labelname[sorted(selected_feats)[i]]) for i in range(len(selected_feats))]))\n",
    "\n",
    "print(f\"\\nTraining R2  = {lr.score(X_train_sel, y_train):.3f}\\nTraining Q2  = {q2:.3f}\")\n",
    "print(f\"Training MAE = {metrics.mean_absolute_error(y_train,y_pred_train):.3f}\")\n",
    "\n",
    "print(\"Training K-fold R2 = {:.3f} (+/- {:.3f})\".format(kfoldscores_self.mean(), kfoldscores_self.std() ** 2))\n",
    "print(f\"\\nTest R2      = {r2_val(y_test,y_pred_test,y_train):.3f}\\nTest MAE     = {metrics.mean_absolute_error(y_test,y_pred_test):.3f}\")\n",
    "\n",
    "plot_fit(y_train,y_pred_train,y_test,y_pred_test,leg=False,sav=False,label=\"y\",loo_pred=loo_train)\n",
    "\n",
    "# define method for converting Model (x1, x2, x3) into list of actual descriptor names.\n",
    "\n",
    "print(df)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write sorted models to Excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-15T20:18:16.132587Z",
     "start_time": "2019-07-15T20:18:16.119971Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('x222', 'x60', 'x9'), ('x261', 'x323', 'x343', 'x39'), ('x116', 'x149', 'x323', 'x9'), ('x105', 'x222', 'x323', 'x7'), ('x105', 'x149', 'x323', 'x7'), ('x215', 'x238', 'x315', 'x365'), ('x106', 'x323', 'x340'), ('x116', 'x222', 'x323', 'x9'), ('x222', 'x323', 'x60', 'x9'), ('x116', 'x312', 'x323', 'x9'), ('x261', 'x323', 'x343', 'x46'), ('x32', 'x323', 'x355'), ('x258', 'x261', 'x9'), ('x116', 'x147', 'x323', 'x9'), ('x261', 'x323', 'x340', 'x39'), ('x261', 'x323', 'x339', 'x46'), ('x129', 'x198', 'x225', 'x236'), ('x119', 'x323', 'x373', 'x7'), ('x111', 'x225', 'x238', 'x263'), ('x28', 'x323', 'x344', 'x361'), ('x147', 'x240', 'x241', 'x365'), ('x13', 'x198', 'x323', 'x327'), ('x11', 'x261', 'x323', 'x9'), ('x116', 'x29', 'x323', 'x374'), ('x240', 'x323', 'x328'), ('x261', 'x323', 'x352', 'x46'), ('x274', 'x323', 'x346', 'x64'), ('x261', 'x323', 'x330', 'x46'), ('x248', 'x313', 'x323', 'x63'), ('x194', 'x323', 'x371'), ('x129', 'x263', 'x63', 'x98'), ('x116', 'x315', 'x323', 'x374'), ('x261', 'x323', 'x59', 'x9'), ('x257', 'x313', 'x363', 'x54'), ('x261', 'x323', 'x355', 'x39'), ('x105', 'x146', 'x323', 'x371'), ('x261', 'x323', 'x341', 'x39'), ('x149', 'x323', 'x60', 'x9'), ('x261', 'x323', 'x330', 'x39'), ('x222', 'x261', 'x344'), ('x261', 'x323', 'x355', 'x46'), ('x261', 'x319', 'x323', 'x9'), ('x105', 'x146', 'x371'), ('x241', 'x363', 'x72'), ('x222', 'x261', 'x323', 'x342'), ('x261', 'x330', 'x39'), ('x28', 'x323', 'x344', 'x373'), ('x116', 'x12', 'x323', 'x9'), ('x261', 'x323', 'x329', 'x46'), ('x105', 'x222', 'x323', 'x9'), ('x105', 'x29', 'x364'), ('x119', 'x261', 'x323', 'x374'), ('x28', 'x343', 'x373'), ('x235', 'x261', 'x323', 'x9'), ('x261', 'x323', 'x328', 'x46'), ('x105', 'x146', 'x323', 'x9'), ('x261', 'x323', 'x340', 'x46'), ('x155', 'x241', 'x70'), ('x182', 'x238', 'x370'), ('x116', 'x325', 'x9'), ('x116', 'x129', 'x323', 'x9'), ('x110', 'x171', 'x261', 'x324'), ('x119', 'x323', 'x373', 'x9'), ('x119', 'x323', 'x33', 'x9'), ('x28', 'x323', 'x343', 'x373'), ('x128', 'x323', 'x329'), ('x129', 'x184', 'x323', 'x341'), ('x105', 'x146', 'x323', 'x374'), ('x238', 'x247', 'x364'), ('x105', 'x241', 'x263', 'x370'), ('x28', 'x323', 'x343', 'x361'), ('x258', 'x261', 'x323', 'x9'), ('x261', 'x323', 'x342', 'x39'), ('x261', 'x3', 'x323', 'x9'), ('x155', 'x323', 'x330'), ('x105', 'x149', 'x323', 'x374'), ('x105', 'x155', 'x323', 'x9'), ('x105', 'x17', 'x323', 'x9'), ('x119', 'x361', 'x9'), ('x105', 'x254', 'x323', 'x9'), ('x238', 'x323', 'x352', 'x363'), ('x225', 'x239', 'x242', 'x363'), ('x116', 'x155', 'x323', 'x9'), ('x119', 'x261', 'x323', 'x9'), ('x188', 'x242', 'x261', 'x365'), ('x261', 'x323', 'x327', 'x46'), ('x261', 'x59', 'x7'), ('x222', 'x261', 'x323', 'x344'), ('x105', 'x222', 'x225', 'x313'), ('x105', 'x146', 'x323', 'x7'), ('x261', 'x323', 'x329', 'x39'), ('x116', 'x175', 'x323', 'x9'), ('x119', 'x323', 'x361', 'x9'), ('x261', 'x323', 'x327', 'x39'), ('x261', 'x323', 'x328', 'x39'), ('x215', 'x241', 'x55', 'x8'), ('x116', 'x323', 'x325', 'x9'), ('x200', 'x241', 'x364'), ('x119', 'x323', 'x63', 'x9'), ('x261', 'x323', 'x339', 'x39'), ('x105', 'x147', 'x323', 'x9'), ('x222', 'x261', 'x323', 'x343'), ('x129', 'x23', 'x313'), ('x105', 'x149', 'x323', 'x371'), ('x261', 'x323', 'x344', 'x39'), ('x225', 'x254', 'x262'), ('x261', 'x323', 'x342', 'x46'), ('x261', 'x323', 'x341', 'x46'), ('x261', 'x323', 'x352', 'x39'), ('x146', 'x323', 'x60', 'x9'), ('x261', 'x323', 'x59', 'x7'), ('x261', 'x323', 'x344', 'x46'), ('x119', 'x260', 'x323', 'x9'), ('x119', 'x323', 'x374', 'x58'), ('x116', 'x169', 'x323', 'x9'), ('x116', 'x146', 'x323', 'x9'), ('x119', 'x261', 'x374'), ('x199', 'x222', 'x323', 'x339'), ('x105', 'x261', 'x323', 'x9'), ('x1', 'x146', 'x319', 'x323'), ('x257', 'x323', 'x342', 'x79'), ('x105', 'x149', 'x323', 'x9'), ('x116', 'x315', 'x323', 'x371'), ('x119', 'x257', 'x323', 'x9'))\n"
     ]
    }
   ],
   "source": [
    "# view best models\n",
    "print(candidates)\n",
    "results.sort_values(by=['Q^2'],ascending=False).head(25)\n",
    "results.to_excel('Ranked MLR Models.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional jobs for model visualization (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View models with a specific number of terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-15T20:19:39.136389Z",
     "start_time": "2019-07-15T20:19:39.127919Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# view models with a specific number of terms\n",
    "number_of_terms = 4\n",
    "selmods = results[results.n_terms <= number_of_terms].sort_values(by=['Q^2'],ascending=False)\n",
    "\n",
    "# example for filtering results\n",
    "selmods2 = results.loc[[i for i in results.index if \"x113\" in results.loc[i,\"Model\"] and \"x49\" not in results.loc[i,\"Model\"]]][results.n_terms < 5].sort_values(by=['Q^2'],ascending=False)\n",
    "selmods2\n",
    "selmods.head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-15T21:35:38.965201Z",
     "start_time": "2019-07-15T21:35:38.717794Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# visualize other models\n",
    "model_sel = results.loc[1,\"Model\"]\n",
    "\n",
    "#other ways of selecting models:\n",
    "# model_sel = results.iloc[selmods.index[3],0]\n",
    "# model_sel = results.iloc[785,0]\n",
    "# model_sel = (\"x100\",\"x31\")\n",
    "\n",
    "\n",
    "selected_feats = [X_labels.index(i) for i in models[model_sel].terms]\n",
    "X_train_sel = X_train_sc[:,selected_feats]\n",
    "X_test_sel = X_test_sc[:,selected_feats]\n",
    "print(models[model_sel].formula)\n",
    "print(\"1 + \"+\" + \".join([X_names[X_labels.index(i)] for i in models[model_sel].terms])+\"\\n\")\n",
    "lr = LinearRegression().fit(X_train_sel,y_train)\n",
    "y_pred_train = lr.predict(X_train_sel)\n",
    "y_pred_test =  lr.predict(X_test_sel)\n",
    "\n",
    "q2,loo_train = loo.q2(X_train_sel,y_train)\n",
    "kfoldscores_self = repeated_k_fold(X_train_sel,y_train,k=5,n=100)\n",
    "\n",
    "print(\"Features: \" + \" + \".join([\"x\"+str(i+1) for i in sorted(selected_feats)]))\n",
    "print(\"\\nParameters:\\n{:10.4f} + \\n\".format(lr.intercept_) + \"\\n\".join([\"{:10.4f} * {}\".format(lr.coef_[i],X_labelname[sorted(selected_feats)[i]]) for i in range(len(selected_feats))]))\n",
    "\n",
    "print(f\"\\nTraining R2  = {lr.score(X_train_sel, y_train):.3f}\\nTraining Q2  = {q2:.3f}\")\n",
    "print(f\"Training MAE = {metrics.mean_absolute_error(y_train,y_pred_train):.3f}\")\n",
    "\n",
    "print(\"Training K-fold R2 = {:.3f} (+/- {:.3f})\".format(kfoldscores_self.mean(), kfoldscores_self.std() ** 2))\n",
    "print(f\"\\nTest R2      = {r2_val(y_test,y_pred_test,y_train):.3f}\\nTest MAE     = {metrics.mean_absolute_error(y_test,y_pred_test):.3f}\")\n",
    "\n",
    "plot_fit(y_train,y_pred_train,y_test,y_pred_test,leg=False,sav=False,label=\"y\",loo_pred=loo_train)\n",
    "model = sm.OLS(y_train, sm.add_constant(pd.DataFrame(X_train_sel))).fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate a model of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-15T21:34:50.963481Z",
     "start_time": "2019-07-15T21:34:50.737676Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: x46 + x261 + x323 + x343\n",
      "\n",
      "Parameters:\n",
      "    1.3856 +    -0.1148 * x46 Min ESP O   -0.1199 * x261 curvedness mean   -0.1934 * x323 Avg H ESP   -0.2776 * x343 R1 Max E\n",
      "\n",
      "Training R2  = 0.829\n",
      "Training Q2  = 0.781\n",
      "Training MAE = 0.109\n",
      "Training K-fold R2 = 0.611 (+/- 0.472)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'y_pred_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-5172e06dbb82>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Training K-fold R2 = {:.3f} (+/- {:.3f})\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkfoldscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkfoldscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m**\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"\\nTest R2      = {r2_val(y_test,y_pred_test,y_train):.3f}\\nTest MAE     = {metrics.mean_absolute_error(y_test,y_pred_test):.3f}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[0mplot_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_pred_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_pred_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mleg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msav\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"y\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloo_pred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mloo_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_pred_test' is not defined"
     ]
    }
   ],
   "source": [
    "#provide an x__ model (string, any order of terms)\n",
    "\n",
    "#provide an x__ model (string, any order of terms)\n",
    "model =('x241', 'x271', 'x522')\n",
    "\n",
    "\n",
    "\n",
    "if (len(model)) == 2:\n",
    "    features_x = str(model[0] +\"+\"+ model[1])\n",
    "if (len(model)) == 3:\n",
    "    features_x = str(model[0] +\"+\"+ model[1]+\"+\"+ model[2])\n",
    "features_py = sorted([X_labels.index(i.strip()) for i in features_x.split(\"+\")])\n",
    "\n",
    "# features_py = []\n",
    "#features = sorted([int(i[1:]) for i in re.findall(\"x\\d+\",features_x)])\n",
    "#features_py = [i-1 for i in features]\n",
    "\n",
    "X_train_sel = X_train_sc[:,features_py]\n",
    "# X_test_sel = X_test_sc[:,features_py]\n",
    "#lr = Ridge(alpha=1E-5).fit(X_train_sel, y_train)\n",
    "lr = LinearRegression().fit(X_train_sel, y_train)\n",
    "y_pred_train = lr.predict(X_train_sel)\n",
    "# y_pred_test =  lr.predict(X_test_sel)\n",
    "q2,loo_train = loo.q2(X_train_sel,y_train)\n",
    "kfoldscores = repeated_k_fold(X_train_sel,y_train,k=4,n=200)\n",
    "print(\"Features: \" + \" + \".join([\"x\"+str(i+1) for i in sorted(features_py)]))\n",
    "print(\"\\nParameters:\\n{:10.4f} + \".format(lr.intercept_) + \"\".join([\"{:10.4f} * {}\".format(lr.coef_[i],X_labelname[sorted(features_py)[i]]) for i in range(len(features_py))]))\n",
    "print(f\"\\nTraining R2  = {lr.score(X_train_sel, y_train):.3f}\\nTraining Q2  = {q2:.3f}\")\n",
    "print(f\"Training MAE = {metrics.mean_absolute_error(y_train,y_pred_train):.3f}\")\n",
    "print(\"Training K-fold R2 = {:.3f} (+/- {:.3f})\".format(kfoldscores.mean(), kfoldscores.std() ** 2))\n",
    "#print(f\"\\nTest R2      = {r2_val(y_test,y_pred_test,y_train):.3f}\\nTest MAE     = {metrics.mean_absolute_error(y_test,y_pred_test):.3f}\")\n",
    "plot_fit(y_train,y_pred_train,y_train,y_pred_train,leg=False,sav=False,label=\"y\",loo_pred=loo_train)\n",
    "model = sm.OLS(y_train, sm.add_constant(pd.DataFrame(X_train_sel))).fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "314px",
    "width": "313px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "325px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": "400"
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 959.666666,
   "position": {
    "height": "981.263px",
    "left": "1534.33px",
    "right": "20px",
    "top": "5px",
    "width": "631.037px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
